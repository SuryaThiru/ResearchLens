{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769c0bc8-a403-4b0b-b0e6-037ebe05c7eb",
   "metadata": {},
   "source": [
    "# Citation Extractor\n",
    "\n",
    "Given a pdf file, an extract of text in the file, fetch all the papers cited in the extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d893704-9eb8-4cba-ac13-cdbb337b5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606a129a-3199-4473-a4ad-4ad86538d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/surya/NEU/CS5100 FAI/Project/pdfreader/\"\n",
    "file = datadir + \"test.pdf\"\n",
    "doc = fitz.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24e408f-9f0f-44ea-b0eb-ac7e6b2b945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = \"\"\"\n",
    "This is the same objective optimized in prior works [49, 38, 1, 26] using the DPO-equivalent reward\n",
    "for the reward class of rφ . In this setting, we can interpret the normalization term in f (rφ, πref , β)\n",
    "as the soft value function of the reference policy πref . While this term does not affect the optimal\n",
    "solution, without it, the policy gradient of the objective could have high variance, making learning\n",
    "unstable. We can accommodate for the normalization term using a learned value function, but that\n",
    "can also be difficult to optimize. Alternatively, prior works have normalized rewards using a human\n",
    "completion baseline, essentially a single sample Monte-Carlo estimate of the normalizing term. In\n",
    "contrast the DPO reparameterization yields a reward function that does not require any baselines.\n",
    "\"\"\"\n",
    "\n",
    "extract = extract.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5cfb4e3-011f-408e-9341-a0de57c75683",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = \"\"\"\n",
    "Visual object tracking studies the joint spatial-temporal localization of objects in videos. From a\n",
    "video and a predefined taxonomy, multiple object tracking (MOT) models simultaneously detect,\n",
    "recognize, and track multiple objects. For example, MOT [54] tracks humans, KITTI [25, 50] tracks\n",
    "pedestrians and cars, and TAO [15] tracks a large taxonomy of 833 categories. In contrast, single\n",
    "object tracking (SOT) follows a single object via a provided initial template of the object, without\n",
    "any detection or recognition. Thus, SOT is often taxonomy-free and operates on generic objects. The\n",
    "community has constructed multiple popular benchmarks to study this problem, including OTB [76],\n",
    "UAV [56], NfS [36], TC-128 [45], NUS-PRO [41], GOT-10k [32], VOT [38], and TrackingNet [57].\n",
    "\"\"\"\n",
    "\n",
    "extract = extract.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d47c5a-7bd6-4bdd-b164-6726eb7b3f34",
   "metadata": {},
   "source": [
    "## Find the extract text in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223749bf-be64-4bf2-957c-9ba40f4f7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057233a1-da2f-421c-96bd-63129a771f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                         \r"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "\n",
    "for page_num in tqdm(range(len(doc)), leave=False):\n",
    "    page = doc.load_page(page_num)  # load the current page\n",
    "    text_blocks = page.get_text_blocks()  # get a list of links on the current page\n",
    "    for block in text_blocks:\n",
    "        text = block[4]\n",
    "\n",
    "        match_score = fuzz.partial_ratio(extract, text)\n",
    "\n",
    "        if match_score >= THRESHOLD:\n",
    "            matches.append((block, page_num, match_score))\n",
    "\n",
    "matches = sorted(matches, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca365a-5134-4e97-9601-11cb4e9c8bb8",
   "metadata": {},
   "source": [
    "Remove matches that are too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208bd5af-9d64-4ec4-8d66-23811413b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINTEXTLEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe19653-2442-4eda-8b4b-ac65b49be709",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = filter(lambda x: len(x[0][4]) > MINTEXTLEN, matches)\n",
    "matches = list(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c30ff3c-b6f9-4548-b91c-946b208c4768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((107.64099884033203,\n",
       "   335.8719482421875,\n",
       "   505.5771789550781,\n",
       "   438.9045104980469,\n",
       "   '2.1\\nVisual object tracking datasets\\nVisual object tracking studies the joint spatial-temporal localization of objects in videos. From a\\nvideo and a predefined taxonomy, multiple object tracking (MOT) models simultaneously detect,\\nrecognize, and track multiple objects. For example, MOT [54] tracks humans, KITTI [25, 50] tracks\\npedestrians and cars, and TAO [15] tracks a large taxonomy of 833 categories. In contrast, single\\nobject tracking (SOT) follows a single object via a provided initial template of the object, without\\nany detection or recognition. Thus, SOT is often taxonomy-free and operates on generic objects. The\\ncommunity has constructed multiple popular benchmarks to study this problem, including OTB [76],\\nUAV [56], NfS [36], TC-128 [45], NUS-PRO [41], GOT-10k [32], VOT [38], and TrackingNet [57].\\n',\n",
       "   7,\n",
       "   0),\n",
       "  2,\n",
       "  100.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf47a88-4008-4965-b92a-841a0ceca0f3",
   "metadata": {},
   "source": [
    "## Get all citation numbers in the text and the corresponding links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2372ef35-e72f-4bea-9b42-c113bd19022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_links(matched_block, matched_page):\n",
    "    # get the matched region\n",
    "    matched_bbox = fitz.Rect(matched_block[:4])\n",
    "\n",
    "    # get the citation links\n",
    "    matched_links = []\n",
    "    \n",
    "    for link in doc[matched_page].get_links():\n",
    "        if link['kind'] == 4:   # internal links\n",
    "            link_bbox = link['from']\n",
    "            if matched_bbox.intersects(link_bbox):\n",
    "                link['from_page'] = matched_page\n",
    "                matched_links.append(link)\n",
    "\n",
    "    return matched_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50081ecb-cf80-4c0e-92f1-e981a494884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_links = []\n",
    "\n",
    "for match in matches:\n",
    "    matched_links.extend(get_matching_links(match[0], match[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d396ac-4ce2-41f2-bccb-da941eed7b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kind': 4,\n",
       "  'xref': 71,\n",
       "  'from': Rect(339.79998779296875, 373.8089904785156, 351.7550048828125, 382.6549987792969),\n",
       "  'page': 11,\n",
       "  'to': Point(108.0, 283.496),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.milan2016mot16',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 72,\n",
       "  'from': Rect(448.7869873046875, 373.8089904785156, 460.74200439453125, 382.6549987792969),\n",
       "  'page': 10,\n",
       "  'to': Point(108.0, 546.128),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.Geiger2012CVPR',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 73,\n",
       "  'from': Rect(463.6969909667969, 373.8089904785156, 475.65301513671875, 382.6549987792969),\n",
       "  'page': 11,\n",
       "  'to': Point(108.0, 411.277),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.Luiten2020IJCV',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 74,\n",
       "  'from': Rect(237.3040008544922, 384.7179870605469, 249.25900268554688, 393.56500244140625),\n",
       "  'page': 9,\n",
       "  'to': Point(108.0, 194.336),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.dave2020tao',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 75,\n",
       "  'from': Rect(488.5539855957031, 417.44500732421875, 500.5090026855469, 426.2919921875),\n",
       "  'page': 12,\n",
       "  'to': Point(108.0, 238.892),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.wu2013online',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 76,\n",
       "  'from': Rect(132.5229949951172, 428.35400390625, 144.47799682617188, 437.20098876953125),\n",
       "  'page': 11,\n",
       "  'to': Point(108.0, 234.55),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.mueller2016benchmark',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 77,\n",
       "  'from': Rect(172.51699829101562, 428.35400390625, 184.4720001220703, 437.20098876953125),\n",
       "  'page': 10,\n",
       "  'to': Point(108.0, 192.35),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.kiani2017need',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 78,\n",
       "  'from': Rect(227.37899780273438, 428.35400390625, 239.33399963378906, 437.20098876953125),\n",
       "  'page': 11,\n",
       "  'to': Point(108.0, 543.606),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.liang2015encoding',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 79,\n",
       "  'from': Rect(293.4119873046875, 428.35400390625, 305.36700439453125, 437.10101318359375),\n",
       "  'page': 11,\n",
       "  'to': Point(108.0, 661.424),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.li2015nus',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 80,\n",
       "  'from': Rect(354.6619873046875, 428.35400390625, 366.61700439453125, 437.20098876953125),\n",
       "  'page': 10,\n",
       "  'to': Point(108.0, 327.969),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.huang2019got',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 81,\n",
       "  'from': Rect(398.260009765625, 428.35400390625, 410.2149963378906, 437.20098876953125),\n",
       "  'page': 10,\n",
       "  'to': Point(108.0, 112.995),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.VOT_TPAMI',\n",
       "  'id': '',\n",
       "  'from_page': 2},\n",
       " {'kind': 4,\n",
       "  'xref': 82,\n",
       "  'from': Rect(488.8389892578125, 428.35400390625, 500.79400634765625, 437.20098876953125),\n",
       "  'page': 11,\n",
       "  'to': Point(108.0, 210.076),\n",
       "  'zoom': 0.0,\n",
       "  'nameddest': 'cite.muller2018trackingnet',\n",
       "  'id': '',\n",
       "  'from_page': 2}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa7efb-ffdf-45cb-af0a-17f2b8b26c9a",
   "metadata": {},
   "source": [
    "Get citation numbers for each each link.\n",
    "\n",
    "Here we also filter out the citation links that are not part of the original extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7946ab2b-c11e-475b-9e45-ad340db58dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 4, 'xref': 71, 'from': Rect(339.79998779296875, 373.8089904785156, 351.7550048828125, 382.6549987792969), 'page': 11, 'to': Point(108.0, 283.496), 'zoom': 0.0, 'nameddest': 'cite.milan2016mot16', 'id': '', 'from_page': 2}\n",
      "[54]\n",
      "\n",
      "{'kind': 4, 'xref': 72, 'from': Rect(448.7869873046875, 373.8089904785156, 460.74200439453125, 382.6549987792969), 'page': 10, 'to': Point(108.0, 546.128), 'zoom': 0.0, 'nameddest': 'cite.Geiger2012CVPR', 'id': '', 'from_page': 2}\n",
      "[25,\n",
      "\n",
      "{'kind': 4, 'xref': 73, 'from': Rect(463.6969909667969, 373.8089904785156, 475.65301513671875, 382.6549987792969), 'page': 11, 'to': Point(108.0, 411.277), 'zoom': 0.0, 'nameddest': 'cite.Luiten2020IJCV', 'id': '', 'from_page': 2}\n",
      "50]\n",
      "\n",
      "{'kind': 4, 'xref': 74, 'from': Rect(237.3040008544922, 384.7179870605469, 249.25900268554688, 393.56500244140625), 'page': 9, 'to': Point(108.0, 194.336), 'zoom': 0.0, 'nameddest': 'cite.dave2020tao', 'id': '', 'from_page': 2}\n",
      "[15]\n",
      "\n",
      "{'kind': 4, 'xref': 75, 'from': Rect(488.5539855957031, 417.44500732421875, 500.5090026855469, 426.2919921875), 'page': 12, 'to': Point(108.0, 238.892), 'zoom': 0.0, 'nameddest': 'cite.wu2013online', 'id': '', 'from_page': 2}\n",
      "[76]\n",
      "\n",
      "{'kind': 4, 'xref': 76, 'from': Rect(132.5229949951172, 428.35400390625, 144.47799682617188, 437.20098876953125), 'page': 11, 'to': Point(108.0, 234.55), 'zoom': 0.0, 'nameddest': 'cite.mueller2016benchmark', 'id': '', 'from_page': 2}\n",
      "[56]\n",
      "\n",
      "{'kind': 4, 'xref': 77, 'from': Rect(172.51699829101562, 428.35400390625, 184.4720001220703, 437.20098876953125), 'page': 10, 'to': Point(108.0, 192.35), 'zoom': 0.0, 'nameddest': 'cite.kiani2017need', 'id': '', 'from_page': 2}\n",
      "[36]\n",
      "\n",
      "{'kind': 4, 'xref': 78, 'from': Rect(227.37899780273438, 428.35400390625, 239.33399963378906, 437.20098876953125), 'page': 11, 'to': Point(108.0, 543.606), 'zoom': 0.0, 'nameddest': 'cite.liang2015encoding', 'id': '', 'from_page': 2}\n",
      "[45]\n",
      "\n",
      "{'kind': 4, 'xref': 79, 'from': Rect(293.4119873046875, 428.35400390625, 305.36700439453125, 437.10101318359375), 'page': 11, 'to': Point(108.0, 661.424), 'zoom': 0.0, 'nameddest': 'cite.li2015nus', 'id': '', 'from_page': 2}\n",
      "[41]\n",
      "\n",
      "{'kind': 4, 'xref': 80, 'from': Rect(354.6619873046875, 428.35400390625, 366.61700439453125, 437.20098876953125), 'page': 10, 'to': Point(108.0, 327.969), 'zoom': 0.0, 'nameddest': 'cite.huang2019got', 'id': '', 'from_page': 2}\n",
      "[32]\n",
      "\n",
      "{'kind': 4, 'xref': 81, 'from': Rect(398.260009765625, 428.35400390625, 410.2149963378906, 437.20098876953125), 'page': 10, 'to': Point(108.0, 112.995), 'zoom': 0.0, 'nameddest': 'cite.VOT_TPAMI', 'id': '', 'from_page': 2}\n",
      "[38]\n",
      "\n",
      "{'kind': 4, 'xref': 82, 'from': Rect(488.8389892578125, 428.35400390625, 500.79400634765625, 437.20098876953125), 'page': 11, 'to': Point(108.0, 210.076), 'zoom': 0.0, 'nameddest': 'cite.muller2018trackingnet', 'id': '', 'from_page': 2}\n",
      "[57]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matched_links_filtered = []\n",
    "\n",
    "# page = doc[matched_page]\n",
    "for link in matched_links:\n",
    "    # keep only citations, not equations and figures\n",
    "    if not link['nameddest'].startswith('cite.'):\n",
    "        continue\n",
    "        \n",
    "    citation_num = doc[link['from_page']].get_text('text', clip=link['from'])\n",
    "    print(link)\n",
    "    print(citation_num)\n",
    "    citation_num = re.findall(r'\\d+', citation_num)\n",
    "\n",
    "    if len(citation_num) == 0:\n",
    "        continue\n",
    "        \n",
    "    citation_num = citation_num[0]\n",
    "\n",
    "    if citation_num not in extract:\n",
    "        continue\n",
    "    \n",
    "    link['citation_number'] = citation_num\n",
    "    matched_links_filtered.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fac2d4d-c71c-4dbb-8019-c505904d1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['54', '25', '50', '15', '76', '56', '36', '45', '41', '32', '38', '57']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['citation_number'] for m in matched_links_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888f9ca-6d81-4d77-8e3c-efacbf06308d",
   "metadata": {},
   "source": [
    "## Get the references for these citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78c695a4-1465-47e3-9952-99db303c33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_references = []\n",
    "\n",
    "for link in matched_links_filtered:\n",
    "    linked_page = doc.load_page(link['page'])\n",
    "    text_blocks = linked_page.get_text(\"blocks\")\n",
    "    citation_num = link['citation_number']\n",
    "    num_pat = r'\\b' + citation_num + r'\\b'\n",
    "    \n",
    "    for text in text_blocks:\n",
    "        # citation number should be present in the initial section of the reference\n",
    "        # if citation_num in text[4][:15]:\n",
    "        if re.search(num_pat, text[4][:15]):\n",
    "            matched_references.append(text[4].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be1c48c9-54d9-47dd-8bf2-0f5971752a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[54] Anton Milan, Laura Leal-Taixé, Ian Reid, Stefan Roth, and Konrad Schindler. Mot16: A benchmark for multi-object tracking. arXiv preprint arXiv:1603.00831, 2016. 3',\n",
       " '[25] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR), 2012. 3',\n",
       " '[50] Jonathon Luiten, Aljosa Osep, Patrick Dendorfer, Philip Torr, Andreas Geiger, Laura Leal-Taixe, and Bastian Leibe. Hota: A higher order metric for evaluating multi-object tracking. International Journal of Computer Vision (IJCV), 2020. 3',\n",
       " '[15] Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, and Deva Ramanan. Tao: A large-scale benchmark for tracking any object. In European conference on computer vision, pages 436–454. Springer, 2020. 3, 4',\n",
       " '[76] Yi Wu, Jongwoo Lim, and Ming-Hsuan Yang. Online object tracking: A benchmark. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2411–2418, 2013. 1, 3',\n",
       " '[56] Matthias Mueller, Neil Smith, and Bernard Ghanem. A benchmark and simulator for uav tracking. In European conference on computer vision, pages 445–461. Springer, 2016. 3',\n",
       " '[36] Hamed Kiani Galoogahi, Ashton Fagg, Chen Huang, Deva Ramanan, and Simon Lucey. Need for speed: A benchmark for higher frame rate object tracking. In Proceedings of the IEEE International Conference on Computer Vision, pages 1125–1134, 2017. 3',\n",
       " '[45] Pengpeng Liang, Erik Blasch, and Haibin Ling. Encoding color information for visual tracking: Algorithms and benchmark. IEEE transactions on image processing, 24(12):5630–5644, 2015. 3',\n",
       " '[41] Annan Li, Min Lin, Yi Wu, Ming-Hsuan Yang, and Shuicheng Yan. Nus-pro: A new visual tracking challenge. IEEE transactions on pattern analysis and machine intelligence, 38(2):335–349, 2015. 3',\n",
       " '[32] Lianghua Huang, Xin Zhao, and Kaiqi Huang. Got-10k: A large high-diversity benchmark for generic object tracking in the wild. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(5):1562– 1577, 2019. 1, 3, 4',\n",
       " '[38] Matej Kristan, Jiri Matas, Aleš Leonardis, Tomas Vojir, Roman Pflugfelder, Gustavo Fernandez, Georg Nebehay, Fatih Porikli, and Luka ˇ Cehovin. A novel performance evaluation methodology for single-target trackers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(11):2137–2155, Nov 2016. 3',\n",
       " '[57] Matthias Muller, Adel Bibi, Silvio Giancola, Salman Alsubaihi, and Bernard Ghanem. Trackingnet: A large-scale dataset and benchmark for object tracking in the wild. In Proceedings of the European conference on computer vision (ECCV), pages 300–317, 2018. 1, 3, 4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_references = list(map(lambda x: x.replace('\\n', ' '), matched_references))\n",
    "matched_references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009777a-7ac1-4aff-9f72-ae05fdb13542",
   "metadata": {},
   "source": [
    "## Format the references\n",
    "\n",
    "Extract clean attributes from the references. This will make the searches more reliable and accurate.\n",
    "\n",
    "Some references:\n",
    "\n",
    "https://anystyle.io/   - Written in ruby, present as cli and web api.\n",
    "\n",
    "https://pypi.org/project/refextract/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063f365-0a05-4616-8fa7-0e87bb70479b",
   "metadata": {},
   "source": [
    "### anystyle.io\n",
    "\n",
    "To avoid setting up ruby and using the libraries. I had to setup my own simple ruby server locally on docker, with some simple sinatra code.\n",
    "\n",
    "The following section would work once the container is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77568d1d-e9ef-4c7c-8949-ff3e3e7fc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_from_reftext(reftext, min_title_len=15):\n",
    "    reftext = reftext.encode(\"utf-8\")\n",
    "    response = requests.post('http://localhost:4567/parse', headers={\"Content-Type\": \"text/plain\"},\n",
    "                        data = reftext)\n",
    "    parsed_data = response.json()\n",
    "\n",
    "    title = parsed_data[0]['title']\n",
    "    title = ' '.join(title)\n",
    "\n",
    "    # date = parsed_data[0]['date']\n",
    "    # date = ' '.join(date)\n",
    "    \n",
    "    assert len(title) >= min_title_len\n",
    "\n",
    "    # title = title + \" \" + date\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f2e2b5b-f8cc-43f1-b9da-e08ea22bf119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "matched_references_title = []\n",
    "\n",
    "for reftext in tqdm(matched_references):\n",
    "    title = get_title_from_reftext(reftext)\n",
    "    matched_references_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2596618-efde-4db0-8103-97827ee1ead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mot16: A benchmark for multi-object tracking',\n",
       " 'Are we ready for autonomous driving? the kitti vision benchmark suite',\n",
       " 'Hota: A higher order metric for evaluating multi-object tracking',\n",
       " 'Tao: A large-scale benchmark for tracking any object',\n",
       " 'Online object tracking: A benchmark',\n",
       " 'A benchmark and simulator for uav tracking',\n",
       " 'Need for speed: A benchmark for higher frame rate object tracking',\n",
       " 'Encoding color information for visual tracking: Algorithms and benchmark',\n",
       " 'Nus-pro: A new visual tracking challenge',\n",
       " 'Got-10k: A large high-diversity benchmark for generic object tracking in the wild',\n",
       " 'A novel performance evaluation methodology for single-target trackers',\n",
       " 'Trackingnet: A large-scale dataset and benchmark for object tracking in the wild']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_references_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cf7c2-1675-4cf3-a671-19bc8a76ea3c",
   "metadata": {},
   "source": [
    "## Get the metadata of these references\n",
    "\n",
    "We will use external services to query for these reference texts and get the relevant metadata.\n",
    "\n",
    "### Observations\n",
    "\n",
    "* using scholarly (which uses google scholar) posed a lot of challenges in networking but worked well, particularly in directing getting the pdf.\n",
    "* using habanero works well for a lot of cases, but fails for a lot of arxiv papers\n",
    "* In a lot of the services, using the wrong year (seems to be common with arxiv - conference mismatches) completely messes up the results\n",
    "* semantic scholar works well, but sometimes can't show pdfs, especially when there is an arxiv paper. I guess pre-prints are not exactly the open-access version of the published paper. But for our purposes it should be good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999c82b-b9ce-49cc-82ea-068d0d4ea7c5",
   "metadata": {},
   "source": [
    "### Semantic scholar\n",
    "\n",
    "I've requested the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ab6143-aa60-48e1-b234-6dd03df3165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "s2_api_key = 'WWxz8zHVUm6DWzkmw6ZSd3eA94kWbbX46Zl5jR11'\n",
    "sch = SemanticScholar(api_key=s2_api_key, timeout=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7790140d-72bc-4b95-afb4-1ac87bea8759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:13<00:00,  6.11s/it]\n"
     ]
    }
   ],
   "source": [
    "matched_references_meta = []\n",
    "\n",
    "for ref in tqdm(matched_references_title):\n",
    "    results = sch.search_paper(ref, limit=1, \n",
    "                               fields=['title', 'paperId', 'externalIds', 'openAccessPdf'])\n",
    "    meta = results[0]\n",
    "    matched_references_meta.append(meta.raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "764ac13f-6913-4199-96df-6f28bfb51576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOT16: A Benchmark for Multi-Object Tracking',\n",
       " 'Are we ready for autonomous driving? The KITTI vision benchmark suite',\n",
       " 'HOTA: A Higher Order Metric for Evaluating Multi-object Tracking',\n",
       " 'TAO: A Large-Scale Benchmark for Tracking Any Object',\n",
       " 'Online Object Tracking: A Benchmark',\n",
       " 'A Benchmark and Simulator for UAV Tracking',\n",
       " 'Need for Speed: A Benchmark for Higher Frame Rate Object Tracking',\n",
       " 'Encoding color information for visual tracking: Algorithms and benchmark',\n",
       " 'NUS-PRO: A New Visual Tracking Challenge',\n",
       " 'GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild',\n",
       " 'A Novel Performance Evaluation Methodology for Single-Target Trackers',\n",
       " 'TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['title'] for m in matched_references_meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8701bfc-619c-467a-9176-dd0601e89dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mot16: A benchmark for multi-object tracking',\n",
       " 'Are we ready for autonomous driving? the kitti vision benchmark suite',\n",
       " 'Hota: A higher order metric for evaluating multi-object tracking',\n",
       " 'Tao: A large-scale benchmark for tracking any object',\n",
       " 'Online object tracking: A benchmark',\n",
       " 'A benchmark and simulator for uav tracking',\n",
       " 'Need for speed: A benchmark for higher frame rate object tracking',\n",
       " 'Encoding color information for visual tracking: Algorithms and benchmark',\n",
       " 'Nus-pro: A new visual tracking challenge',\n",
       " 'Got-10k: A large high-diversity benchmark for generic object tracking in the wild',\n",
       " 'A novel performance evaluation methodology for single-target trackers',\n",
       " 'Trackingnet: A large-scale dataset and benchmark for object tracking in the wild']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_references_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cc079-f8a5-4ce6-b7bc-beeaf73ba631",
   "metadata": {},
   "source": [
    "## Access the PDFs from metadata\n",
    "\n",
    "### Observations\n",
    "\n",
    "* When a DoI is present, open access button is a good API to get the pdf url from DOI. However, it is not perfect.\n",
    "* Open access pdf search is integrated directly into semantic scholar. This sometimes gets the pdf. If it is an arxiv paper, we can use the arxiv id to get the pdfs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f203d309-1c04-4de2-83ce-ee8481fd7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta in matched_references_meta:\n",
    "    if meta['openAccessPdf'] is not None:\n",
    "        meta['pdf_url'] = meta['openAccessPdf']['url']\n",
    "    elif 'ArXiv' in meta['externalIds']:\n",
    "        meta['pdf_url'] = f\"https://arxiv.org/pdf/{meta['externalIds']['ArXiv']}.pdf\"\n",
    "    else:\n",
    "        meta['pdf_url'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67d4760b-ba5b-4bcd-9eec-c2e0574c4af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://arxiv.org/pdf/1603.00831.pdf',\n",
       " None,\n",
       " 'https://link.springer.com/content/pdf/10.1007/s11263-020-01375-2.pdf',\n",
       " 'https://arxiv.org/pdf/2005.10356',\n",
       " 'http://faculty.ucmerced.edu/mhyang/papers/cvpr13_benchmark.pdf',\n",
       " None,\n",
       " 'https://arxiv.org/pdf/1703.05884',\n",
       " None,\n",
       " None,\n",
       " 'https://arxiv.org/pdf/1810.11981.pdf',\n",
       " 'http://pure-oai.bham.ac.uk/ws/files/26149101/performance_evaluation_methodology.pdf',\n",
       " 'https://arxiv.org/pdf/1803.10794']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['pdf_url'] for m in matched_references_meta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b3d0e-22f3-47a3-b56e-857d068368e6",
   "metadata": {},
   "source": [
    "## Download the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3655426f-7d7d-46b3-a97a-6cd72152fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperdir = '/home/surya/NEU/CS5100 FAI/Project/pdfreader/python/papers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92f58d98-7b2e-4a37-ba0a-9867bd1509e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:05<00:00,  5.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for meta in tqdm(matched_references_meta):\n",
    "    paperId = meta['paperId']\n",
    "    pdf = meta['pdf_url']\n",
    "\n",
    "    if pdf is None:\n",
    "        continue        \n",
    "\n",
    "    file = Path(f\"{paperdir}/{paperId}.pdf\")\n",
    "    \n",
    "    # download\n",
    "    response = requests.get(pdf)\n",
    "    file.write_bytes(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9089f4-aad8-4724-ab81-1c55aaa83cdd",
   "metadata": {},
   "source": [
    "# Problems\n",
    "\n",
    "Selection across paragraphs, pages.\n",
    "\n",
    "Paragraphs broken by images and tables.\n",
    "\n",
    "~~Above problems require using multiple block matches, right now only using the top match.~~\n",
    "\n",
    "Make it work for name-based citation\n",
    "\n",
    "Make it work for 2-column references?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
