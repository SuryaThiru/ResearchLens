{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769c0bc8-a403-4b0b-b0e6-037ebe05c7eb",
   "metadata": {},
   "source": [
    "# Citation Extractor\n",
    "\n",
    "Given a pdf file, an extract of text in the file, fetch all the papers cited in the extract.\n",
    "\n",
    "\n",
    "TODO:\n",
    "\n",
    "- [ ] The DOIs are not accurate\n",
    "- [ ] Make it work for name-based citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d893704-9eb8-4cba-ac13-cdbb337b5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606a129a-3199-4473-a4ad-4ad86538d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../test2.pdf\"\n",
    "doc = fitz.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24e408f-9f0f-44ea-b0eb-ac7e6b2b945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = \"\"\"\n",
    "This is the same objective optimized in prior works [49, 38, 1, 26] using the DPO-equivalent reward\n",
    "for the reward class of rφ . In this setting, we can interpret the normalization term in f (rφ, πref , β)\n",
    "as the soft value function of the reference policy πref . While this term does not affect the optimal\n",
    "solution, without it, the policy gradient of the objective could have high variance, making learning\n",
    "unstable. We can accommodate for the normalization term using a learned value function, but that\n",
    "can also be difficult to optimize. Alternatively, prior works have normalized rewards using a human\n",
    "completion baseline, essentially a single sample Monte-Carlo estimate of the normalizing term. In\n",
    "contrast the DPO reparameterization yields a reward function that does not require any baselines.\n",
    "\"\"\"\n",
    "\n",
    "extract = extract.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d47c5a-7bd6-4bdd-b164-6726eb7b3f34",
   "metadata": {},
   "source": [
    "## Find the extract text in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223749bf-be64-4bf2-957c-9ba40f4f7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057233a1-da2f-421c-96bd-63129a771f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                         \r"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "\n",
    "for page_num in tqdm(range(len(doc)), leave=False):\n",
    "    page = doc.load_page(page_num)  # load the current page\n",
    "    text_blocks = page.get_text_blocks()  # get a list of links on the current page\n",
    "    for block in text_blocks:\n",
    "        text = block[4]\n",
    "        \n",
    "        match_score = fuzz.partial_ratio(extract, text)\n",
    "\n",
    "        if match_score >= THRESHOLD:\n",
    "            matches.append((block, page_num, match_score))\n",
    "\n",
    "matches = sorted(matches, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a791ca97-c898-41d6-96fe-5b83422e0088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((107.69100189208984,\n",
       "   634.4305419921875,\n",
       "   505.1564636230469,\n",
       "   722.7994995117188,\n",
       "   'This is the same objective optimized in prior works [49, 38, 1, 26] using the DPO-equivalent reward\\nfor the reward class of rϕ. In this setting, we can interpret the normalization term in f(rϕ, πref, β)\\nas the soft value function of the reference policy πref. While this term does not affect the optimal\\nsolution, without it, the policy gradient of the objective could have high variance, making learning\\nunstable. We can accommodate for the normalization term using a learned value function, but that\\ncan also be difficult to optimize. Alternatively, prior works have normalized rewards using a human\\ncompletion baseline, essentially a single sample Monte-Carlo estimate of the normalizing term. In\\ncontrast the DPO reparameterization yields a reward function that does not require any baselines.\\n',\n",
       "   25,\n",
       "   0),\n",
       "  5,\n",
       "  99.24812030075188)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c71367-9fd5-4150-b429-e1dc377162e2",
   "metadata": {},
   "source": [
    "For now keep the top match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6406514e-688c-46ba-bfa6-58efccf6549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_block = matches[0][0]\n",
    "matched_page = matches[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf47a88-4008-4965-b92a-841a0ceca0f3",
   "metadata": {},
   "source": [
    "## Get all citation numbers in the text and the corresponding links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f04dc339-5b4d-4635-a637-e5be3bc1a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_bbox = fitz.Rect(matched_block[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc3589-db08-4325-b67d-9f169d8a3d7d",
   "metadata": {},
   "source": [
    "Get citing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2171ec1f-6d17-460f-b6f0-4ab9de62ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_links = []\n",
    "\n",
    "for link in doc[matched_page].get_links():\n",
    "    if link['kind'] == 4:   # internal links\n",
    "        link_bbox = link['from']\n",
    "        if matched_bbox.intersects(link_bbox):\n",
    "            matched_links.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa7efb-ffdf-45cb-af0a-17f2b8b26c9a",
   "metadata": {},
   "source": [
    "Get citation numbers for each each link.\n",
    "\n",
    "Here we also filter out the citation links that are not part of the original extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7946ab2b-c11e-475b-9e45-ad340db58dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_links_filtered = []\n",
    "\n",
    "page = doc[matched_page]\n",
    "for link in matched_links:\n",
    "    citation_num = page.get_text('text', clip=link['from'])\n",
    "    citation_num = re.findall(r'\\d+', citation_num)[0]\n",
    "\n",
    "    if citation_num not in extract:\n",
    "        continue\n",
    "    \n",
    "    link['citation_number'] = citation_num\n",
    "    matched_links_filtered.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fac2d4d-c71c-4dbb-8019-c505904d1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['49', '38', '1', '26']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['citation_number'] for m in matched_links_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888f9ca-6d81-4d77-8e3c-efacbf06308d",
   "metadata": {},
   "source": [
    "## Get the references for these citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c695a4-1465-47e3-9952-99db303c33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_references = []\n",
    "\n",
    "for link in matched_links_filtered:\n",
    "    linked_page = doc.load_page(link['page'])\n",
    "    text_blocks = linked_page.get_text(\"blocks\")\n",
    "    citation_num = link['citation_number']\n",
    "    num_pat = r'\\b' + citation_num + r'\\b'\n",
    "    \n",
    "    for text in text_blocks:\n",
    "        # citation number should be present in the initial section of the reference\n",
    "        # if citation_num in text[4][:15]:\n",
    "        if re.search(num_pat, text[4][:15]):\n",
    "            matched_references.append(text[4].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1c48c9-54d9-47dd-8bf2-0f5971752a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[49] D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei, P. Christiano, andG. Irving. Fine-tuning language models from human preferences, 2020.',\n",
       " '[38] N. Stiennon, L. Ouyang, J. Wu, D. M. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, andP. Christiano. Learning to summarize from human feedback, 2022.',\n",
       " '[1] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli,T. Henighan, N. Joseph, S. Kadavath, J. Kernion, T. Conerly, S. El-Showk, N. Elhage, Z. Hatfield-Dodds, D. Hernandez, T. Hume, S. Johnston, S. Kravec, L. Lovitt, N. Nanda, C. Olsson,D. Amodei, T. Brown, J. Clark, S. McCandlish, C. Olah, B. Mann, and J. Kaplan. Training ahelpful and harmless assistant with reinforcement learning from human feedback, 2022.',\n",
       " '[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder,P. F. Christiano, J. Leike, and R. Lowe. Training language models to follow instructions withhuman feedback. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh,editors, Advances in Neural Information Processing Systems, volume 35, pages 27730–27744.Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_references = list(map(lambda x: x.replace('\\n', ''), matched_references))\n",
    "matched_references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cf7c2-1675-4cf3-a671-19bc8a76ea3c",
   "metadata": {},
   "source": [
    "## Get the metadata of these references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353410d-897e-4f2f-835c-b4b593d505d9",
   "metadata": {},
   "source": [
    "### Habanero\n",
    "\n",
    "Get the DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9670978d-8715-4c5d-9094-a3bf3757707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from habanero import Crossref\n",
    "cr = Crossref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29552cc6-23a0-4936-84dd-54cfc0d19828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "matched_references_meta = []\n",
    "\n",
    "for ref in tqdm(matched_references):\n",
    "    results = cr.works(query = ref, limit = 1)\n",
    "    meta = results['message']['items'][0]\n",
    "    matched_references_meta.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "175391b7-c92e-4ea0-9d3a-0d7177ca915d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10.31235/osf.io/sthwk',\n",
       " '10.3102/1892071',\n",
       " '10.1145/3531146.3533229',\n",
       " '10.47205/jdss.2021(2-iv)74']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['DOI'] for m in matched_references_meta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cc079-f8a5-4ce6-b7bc-beeaf73ba631",
   "metadata": {},
   "source": [
    "### OpenAccessButton\n",
    "\n",
    "Get the open access PDF urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c54ac8b5-e71f-414a-bbff-d1f3b635365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5ca99b3-6e50-4324-b6eb-bec6735cc825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta in matched_references_meta:\n",
    "    doi = meta['DOI']\n",
    "    url = f\"https://api.openaccessbutton.org/find?id={doi}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'url' not in data and data['metadata']['publisher'] == 'ACM':\n",
    "            pdf_url = f\"https://dl.acm.org/doi/pdf/{doi}\"\n",
    "        else:\n",
    "            pdf_url = data.get('url')\n",
    "\n",
    "        meta['pdf_url'] = pdf_url\n",
    "    else:\n",
    "        raise ValueError(\"failed request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67d4760b-ba5b-4bcd-9eec-c2e0574c4af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://osf.io/sthwk/download',\n",
       " None,\n",
       " 'https://dl.acm.org/doi/pdf/10.1145/3531146.3533229',\n",
       " 'https://jdss.org.pk/issues/v2/4/water-sharing-issues-in-pakistan-impacts-on-inter-provincial-relations.pdf']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['pdf_url'] for m in matched_references_meta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b3d0e-22f3-47a3-b56e-857d068368e6",
   "metadata": {},
   "source": [
    "## Download the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92f58d98-7b2e-4a37-ba0a-9867bd1509e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 27548.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for meta in tqdm(matched_references_meta):\n",
    "    doi = meta['DOI']\n",
    "    pdf = meta['pdf_url']\n",
    "\n",
    "    file = Path(f\"papers/{doi.replace('/', '_')}.pdf\")\n",
    "    \n",
    "    # download\n",
    "    # response = requests.get(pdf)\n",
    "    # file.write_bytes(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9089f4-aad8-4724-ab81-1c55aaa83cdd",
   "metadata": {},
   "source": [
    "# Problems\n",
    "\n",
    "Selection across paragraphs, pages.\n",
    "\n",
    "Paragraphs broken by images and tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
