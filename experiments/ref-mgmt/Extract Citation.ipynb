{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769c0bc8-a403-4b0b-b0e6-037ebe05c7eb",
   "metadata": {},
   "source": [
    "# Citation Extractor\n",
    "\n",
    "Given a pdf file, an extract of text in the file, fetch all the papers cited in the extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d893704-9eb8-4cba-ac13-cdbb337b5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606a129a-3199-4473-a4ad-4ad86538d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/surya/NEU/CS5100 FAI/Project/pdfreader/\"\n",
    "file = datadir + \"test2.pdf\"\n",
    "doc = fitz.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24e408f-9f0f-44ea-b0eb-ac7e6b2b945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = \"\"\"\n",
    "This is the same objective optimized in prior works [49, 38, 1, 26] using the DPO-equivalent reward\n",
    "for the reward class of rφ . In this setting, we can interpret the normalization term in f (rφ, πref , β)\n",
    "as the soft value function of the reference policy πref . While this term does not affect the optimal\n",
    "solution, without it, the policy gradient of the objective could have high variance, making learning\n",
    "unstable. We can accommodate for the normalization term using a learned value function, but that\n",
    "can also be difficult to optimize. Alternatively, prior works have normalized rewards using a human\n",
    "completion baseline, essentially a single sample Monte-Carlo estimate of the normalizing term. In\n",
    "contrast the DPO reparameterization yields a reward function that does not require any baselines.\n",
    "\"\"\"\n",
    "\n",
    "extract = extract.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d47c5a-7bd6-4bdd-b164-6726eb7b3f34",
   "metadata": {},
   "source": [
    "## Find the extract text in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223749bf-be64-4bf2-957c-9ba40f4f7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057233a1-da2f-421c-96bd-63129a771f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                         \r"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "\n",
    "for page_num in tqdm(range(len(doc)), leave=False):\n",
    "    page = doc.load_page(page_num)  # load the current page\n",
    "    text_blocks = page.get_text_blocks()  # get a list of links on the current page\n",
    "    for block in text_blocks:\n",
    "        text = block[4]\n",
    "\n",
    "        match_score = fuzz.partial_ratio(extract, text)\n",
    "\n",
    "        if match_score >= THRESHOLD:\n",
    "            matches.append((block, page_num, match_score))\n",
    "\n",
    "matches = sorted(matches, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca365a-5134-4e97-9601-11cb4e9c8bb8",
   "metadata": {},
   "source": [
    "Remove matches that are too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208bd5af-9d64-4ec4-8d66-23811413b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINTEXTLEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe19653-2442-4eda-8b4b-ac65b49be709",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = filter(lambda x: len(x[0][4]) > MINTEXTLEN, matches)\n",
    "matches = list(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c30ff3c-b6f9-4548-b91c-946b208c4768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((107.69100189208984,\n",
       "   634.4305419921875,\n",
       "   505.1564636230469,\n",
       "   722.7994995117188,\n",
       "   'This is the same objective optimized in prior works [49, 38, 1, 26] using the DPO-equivalent reward\\nfor the reward class of rϕ. In this setting, we can interpret the normalization term in f(rϕ, πref, β)\\nas the soft value function of the reference policy πref. While this term does not affect the optimal\\nsolution, without it, the policy gradient of the objective could have high variance, making learning\\nunstable. We can accommodate for the normalization term using a learned value function, but that\\ncan also be difficult to optimize. Alternatively, prior works have normalized rewards using a human\\ncompletion baseline, essentially a single sample Monte-Carlo estimate of the normalizing term. In\\ncontrast the DPO reparameterization yields a reward function that does not require any baselines.\\n',\n",
       "   26,\n",
       "   0),\n",
       "  5,\n",
       "  99.24812030075188)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c71367-9fd5-4150-b429-e1dc377162e2",
   "metadata": {},
   "source": [
    "For now keep the top match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6406514e-688c-46ba-bfa6-58efccf6549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_block = matches[0][0]\n",
    "matched_page = matches[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf47a88-4008-4965-b92a-841a0ceca0f3",
   "metadata": {},
   "source": [
    "## Get all citation numbers in the text and the corresponding links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f04dc339-5b4d-4635-a637-e5be3bc1a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_bbox = fitz.Rect(matched_block[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc3589-db08-4325-b67d-9f169d8a3d7d",
   "metadata": {},
   "source": [
    "Get citing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2171ec1f-6d17-460f-b6f0-4ab9de62ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_links = []\n",
    "\n",
    "for link in doc[matched_page].get_links():\n",
    "    if link['kind'] == 4:   # internal links\n",
    "        link_bbox = link['from']\n",
    "        if matched_bbox.intersects(link_bbox):\n",
    "            matched_links.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa7efb-ffdf-45cb-af0a-17f2b8b26c9a",
   "metadata": {},
   "source": [
    "Get citation numbers for each each link.\n",
    "\n",
    "Here we also filter out the citation links that are not part of the original extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7946ab2b-c11e-475b-9e45-ad340db58dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_links_filtered = []\n",
    "\n",
    "page = doc[matched_page]\n",
    "for link in matched_links:\n",
    "    # keep only citations, not equations and figures\n",
    "    if not link['nameddest'].startswith('cite.'):\n",
    "        continue\n",
    "        \n",
    "    citation_num = page.get_text('text', clip=link['from'])\n",
    "    citation_num = re.findall(r'\\d+', citation_num)[0]\n",
    "\n",
    "    if citation_num not in extract:\n",
    "        continue\n",
    "    \n",
    "    link['citation_number'] = citation_num\n",
    "    matched_links_filtered.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fac2d4d-c71c-4dbb-8019-c505904d1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['49', '38', '1', '26']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['citation_number'] for m in matched_links_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888f9ca-6d81-4d77-8e3c-efacbf06308d",
   "metadata": {},
   "source": [
    "## Get the references for these citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c695a4-1465-47e3-9952-99db303c33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_references = []\n",
    "\n",
    "for link in matched_links_filtered:\n",
    "    linked_page = doc.load_page(link['page'])\n",
    "    text_blocks = linked_page.get_text(\"blocks\")\n",
    "    citation_num = link['citation_number']\n",
    "    num_pat = r'\\b' + citation_num + r'\\b'\n",
    "    \n",
    "    for text in text_blocks:\n",
    "        # citation number should be present in the initial section of the reference\n",
    "        # if citation_num in text[4][:15]:\n",
    "        if re.search(num_pat, text[4][:15]):\n",
    "            matched_references.append(text[4].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1c48c9-54d9-47dd-8bf2-0f5971752a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[49] D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei, P. Christiano, and G. Irving. Fine-tuning language models from human preferences, 2020.',\n",
       " '[38] N. Stiennon, L. Ouyang, J. Wu, D. M. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, and P. Christiano. Learning to summarize from human feedback, 2022.',\n",
       " '[1] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli, T. Henighan, N. Joseph, S. Kadavath, J. Kernion, T. Conerly, S. El-Showk, N. Elhage, Z. Hatfield- Dodds, D. Hernandez, T. Hume, S. Johnston, S. Kravec, L. Lovitt, N. Nanda, C. Olsson, D. Amodei, T. Brown, J. Clark, S. McCandlish, C. Olah, B. Mann, and J. Kaplan. Training a helpful and harmless assistant with reinforcement learning from human feedback, 2022.',\n",
       " '[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe. Training language models to follow instructions with human feedback. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 27730–27744. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/ paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_references = list(map(lambda x: x.replace('\\n', ' '), matched_references))\n",
    "matched_references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009777a-7ac1-4aff-9f72-ae05fdb13542",
   "metadata": {},
   "source": [
    "## Format the references\n",
    "\n",
    "Extract clean attributes from the references. This will make the searches more reliable and accurate.\n",
    "\n",
    "Some references:\n",
    "\n",
    "https://anystyle.io/   - Written in ruby, present as cli and web api.\n",
    "\n",
    "https://pypi.org/project/refextract/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063f365-0a05-4616-8fa7-0e87bb70479b",
   "metadata": {},
   "source": [
    "### anystyle.io\n",
    "\n",
    "To avoid setting up ruby and using the libraries. I had to setup my own simple ruby server locally on docker, with some simple sinatra code.\n",
    "\n",
    "The following section would work once the container is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77568d1d-e9ef-4c7c-8949-ff3e3e7fc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_from_reftext(reftext, min_title_len=15):\n",
    "    reftext = reftext.encode(\"utf-8\")\n",
    "    response = requests.post('http://localhost:4567/parse', headers={\"Content-Type\": \"text/plain\"},\n",
    "                        data = reftext)\n",
    "    parsed_data = response.json()\n",
    "\n",
    "    title = parsed_data[0]['title']\n",
    "    title = ' '.join(title)\n",
    "\n",
    "    # date = parsed_data[0]['date']\n",
    "    # date = ' '.join(date)\n",
    "    \n",
    "    assert len(title) >= min_title_len\n",
    "\n",
    "    # title = title + \" \" + date\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2e2b5b-f8cc-43f1-b9da-e08ea22bf119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.07it/s]\n"
     ]
    }
   ],
   "source": [
    "matched_references_title = []\n",
    "\n",
    "for reftext in tqdm(matched_references):\n",
    "    title = get_title_from_reftext(reftext)\n",
    "    matched_references_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2596618-efde-4db0-8103-97827ee1ead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fine-tuning language models from human preferences',\n",
       " 'Learning to summarize from human feedback',\n",
       " 'Training a helpful and harmless assistant with reinforcement learning from human feedback',\n",
       " 'Training language models to follow instructions with human feedback']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_references_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cf7c2-1675-4cf3-a671-19bc8a76ea3c",
   "metadata": {},
   "source": [
    "## Get the metadata of these references\n",
    "\n",
    "We will use external services to query for these reference texts and get the relevant metadata.\n",
    "\n",
    "### Observations\n",
    "\n",
    "* using scholarly (which uses google scholar) posed a lot of challenges in networking but worked well, particularly in directing getting the pdf.\n",
    "* using habanero works well for a lot of cases, but fails for a lot of arxiv papers\n",
    "* In a lot of the services, using the wrong year (seems to be common with arxiv - conference mismatches) completely messes up the results\n",
    "* semantic scholar works well, but sometimes can't show pdfs, especially when there is an arxiv paper. I guess pre-prints are not exactly the open-access version of the published paper. But for our purposes it should be good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999c82b-b9ce-49cc-82ea-068d0d4ea7c5",
   "metadata": {},
   "source": [
    "### Semantic scholar\n",
    "\n",
    "I've requested the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40ab6143-aa60-48e1-b234-6dd03df3165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "s2_api_key = 'WWxz8zHVUm6DWzkmw6ZSd3eA94kWbbX46Zl5jR11'\n",
    "sch = SemanticScholar(api_key=s2_api_key, timeout=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7790140d-72bc-4b95-afb4-1ac87bea8759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:34<00:00,  8.60s/it]\n"
     ]
    }
   ],
   "source": [
    "matched_references_meta = []\n",
    "\n",
    "for ref in tqdm(matched_references_title):\n",
    "    results = sch.search_paper(ref, limit=1, \n",
    "                               fields=['title', 'paperId', 'externalIds', 'openAccessPdf'])\n",
    "    meta = results[0]\n",
    "    matched_references_meta.append(meta.raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "764ac13f-6913-4199-96df-6f28bfb51576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fine-Tuning Language Models from Human Preferences',\n",
       " 'Learning to summarize from human feedback',\n",
       " 'Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback',\n",
       " 'Training language models to follow instructions with human feedback']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['title'] for m in matched_references_meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8701bfc-619c-467a-9176-dd0601e89dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fine-tuning language models from human preferences',\n",
       " 'Learning to summarize from human feedback',\n",
       " 'Training a helpful and harmless assistant with reinforcement learning from human feedback',\n",
       " 'Training language models to follow instructions with human feedback']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_references_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cc079-f8a5-4ce6-b7bc-beeaf73ba631",
   "metadata": {},
   "source": [
    "## Access the PDFs from metadata\n",
    "\n",
    "### Observations\n",
    "\n",
    "* When a DoI is present, open access button is a good API to get the pdf url from DOI. However, it is not perfect.\n",
    "* Open access pdf search is integrated directly into semantic scholar. This sometimes gets the pdf. If it is an arxiv paper, we can use the arxiv id to get the pdfs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f203d309-1c04-4de2-83ce-ee8481fd7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta in matched_references_meta:\n",
    "    if meta['openAccessPdf'] is not None:\n",
    "        meta['pdf_url'] = meta['openAccessPdf']['url']\n",
    "    elif 'ArXiv' in meta['externalIds']:\n",
    "        meta['pdf_url'] = f\"https://arxiv.org/pdf/{meta['externalIds']['ArXiv']}.pdf\"\n",
    "    else:\n",
    "        meta['pdf_url'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67d4760b-ba5b-4bcd-9eec-c2e0574c4af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://arxiv.org/pdf/1909.08593.pdf',\n",
       " 'https://arxiv.org/pdf/2009.01325.pdf',\n",
       " 'http://arxiv.org/pdf/2204.05862',\n",
       " 'https://arxiv.org/pdf/2203.02155.pdf']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['pdf_url'] for m in matched_references_meta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b3d0e-22f3-47a3-b56e-857d068368e6",
   "metadata": {},
   "source": [
    "## Download the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3655426f-7d7d-46b3-a97a-6cd72152fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperdir = '/home/surya/NEU/CS5100 FAI/Project/pdfreader/python/papers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92f58d98-7b2e-4a37-ba0a-9867bd1509e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for meta in tqdm(matched_references_meta):\n",
    "    paperId = meta['paperId']\n",
    "    pdf = meta['pdf_url']\n",
    "\n",
    "    if pdf is None:\n",
    "        continue        \n",
    "\n",
    "    file = Path(f\"{paperdir}/{paperId}.pdf\")\n",
    "    \n",
    "    # download\n",
    "    response = requests.get(pdf)\n",
    "    file.write_bytes(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9089f4-aad8-4724-ab81-1c55aaa83cdd",
   "metadata": {},
   "source": [
    "# Problems\n",
    "\n",
    "Selection across paragraphs, pages.\n",
    "\n",
    "Paragraphs broken by images and tables.\n",
    "\n",
    "Above problems require using multiple block matches, right now only using the top match.\n",
    "\n",
    "Make it work for name-based citation\n",
    "\n",
    "Make it work for 2-column references?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
